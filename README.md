# Knowledge-Distillation

Part of my work on designing lighter neural networks on a Summer Research Fellowship from the Indian Academy of Sciences.
The code shows a simple implementation of a teacher-student network on CIFAR-10. 
Full report can be found here: http://reports.ias.ac.in/report/21075/knowledge-distillation-and-the-design-of-fpga-deployable-compressed-deep-neural-networks.
The article here is an easier-to-understand TL;DR version: https://devopedia.org/knowledge-distillation

